# ğŸ¤– Coda - Code Assistant

A powerful, multi-provider AI code assistant that brings the best of AI-powered development directly to your terminal. Coda seamlessly integrates with multiple AI providers while maintaining a consistent, developer-friendly interface.

## âœ¨ What is Coda?

Coda is your AI pair programmer that:
- ğŸš€ **Lives in your terminal**: Works right where you code, integrated into your development workflow
- ğŸ”Œ **Connects to any AI**: Use Oracle OCI GenAI, local Ollama models, OpenAI, Anthropic, or any LiteLLM-supported provider
- ğŸ’» **Thinks like a developer**: Specialized modes for writing, debugging, explaining, and reviewing code
- ğŸ”„ **Remembers context**: Save and resume conversations, branch off interesting threads
- ğŸ› ï¸ **Takes action**: Integrated tools for file operations, web searches, and more via Model Context Protocol (MCP)

## ğŸ¯ Key Features

- ğŸŒ **Multi-Provider Support**: Oracle OCI GenAI, Ollama (local), OpenAI, Anthropic, Google, and 100+ more via LiteLLM
- ğŸ’» **CLI-First Design**: Built for developers who live in the terminal
- ğŸ§  **Smart Modes**: Specialized AI personalities for different tasks (code, debug, explain, review)
- ğŸ’¾ **Session Management**: Never lose a conversation - save, resume, and branch discussions
- ğŸ¨ **Beautiful Interface**: Rich terminal UI with syntax highlighting and multiple themes
- âš¡ **Real-time Streaming**: See responses as they're generated
- ğŸ”§ **Tool Integration**: File operations, web search, and custom tools via MCP
- ğŸŒˆ **Customizable**: Themes, key bindings, and behavior settings

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/djvolz/coda-code-assistant.git
cd coda-code-assistant

# Install with uv (recommended)
uv sync

# Run Coda
uv run coda
```

## ğŸš€ Quick Start

### Basic Usage

```bash
# Start interactive chat with default provider (Ollama)
uv run coda

# Use a specific provider
uv run coda --provider openai --model gpt-4
uv run coda --provider oci --model cohere.command-r-plus

# One-shot command
uv run coda --one-shot "explain this regex: ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
```

### Provider Setup

#### ğŸ  Ollama (Local, No API Key Required)
```bash
# Install Ollama from https://ollama.ai
ollama pull llama3.1
ollama serve  # Run in separate terminal
uv run coda --provider ollama
```

#### â˜ï¸ Oracle OCI GenAI
```bash
export OCI_COMPARTMENT_ID="ocid1.compartment.oc1..."
uv run coda --provider oci --model cohere.command-r-plus
```

#### ğŸ¤– OpenAI
```bash
export OPENAI_API_KEY="sk-..."
uv run coda --provider openai --model gpt-4
```

## ğŸ’¡ Usage Examples

### Interactive Development
```bash
# Start a coding session
uv run coda

# In the chat:
You: /mode code
You: Write a Python function to parse JSON with error handling
You: /mode debug
You: Help me fix this TypeError in @main.py
You: /mode review
You: Review the security of @auth.py
```

### Session Management
```bash
# Save your conversation
/sessions save my-feature-discussion

# List previous sessions
/sessions list

# Resume a session
/sessions load my-feature-discussion
```

### Customization
```bash
# Change theme
/theme dracula

# Export conversation
/export markdown conversation.md

# Configure settings
/config edit
```

## ğŸ› ï¸ Development

```bash
# Install development dependencies
uv sync --dev

# Run tests
uv run pytest

# Format code
uv run black .
uv run ruff check --fix .

# Type checking
uv run mypy coda
```

## ğŸ—ï¸ Architecture

Coda is built with a modular architecture:

```
coda/
â”œâ”€â”€ core/       # Core chat engine and session management
â”œâ”€â”€ providers/  # AI provider implementations
â”œâ”€â”€ cli/        # Terminal interface and commands
â”œâ”€â”€ tools/      # MCP tool integrations
â”œâ”€â”€ config/     # Configuration management
â””â”€â”€ utils/      # Shared utilities
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) and check out our [AGENTS.md](AGENTS.md) file for AI-assisted development guidelines.

## ğŸ“ License

[To be determined]

## ğŸ™ Acknowledgments

Built with:
- [LiteLLM](https://github.com/BerriAI/litellm) - Unified LLM API
- [Rich](https://github.com/Textualize/rich) - Beautiful terminal formatting
- [Prompt Toolkit](https://github.com/prompt-toolkit/python-prompt-toolkit) - Advanced CLI interactions
- [Model Context Protocol](https://modelcontext.dev/) - Tool integration standard